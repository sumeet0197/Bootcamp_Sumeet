{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c03ea1a",
   "metadata": {},
   "source": [
    "# HW04 â€” Data Acquisition & Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d255b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime as dt\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from src.config import load_env\n",
    "paths = load_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1feea",
   "metadata": {},
   "source": [
    "# 1) API Pull (AAPL via yfinance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "_ts = dt.datetime.now().strftime('%Y%m%d-%H%M')\n",
    "df_api = yf.download(ticker, period='6mo', interval='1d', auto_adjust=False)\n",
    "df_api.reset_index(inplace=True)\n",
    "assert set(['Date','Open','High','Low','Close','Adj Close','Volume']).issubset(df_api.columns)\n",
    "df_api['Date'] = pd.to_datetime(df_api['Date'])\n",
    "print('API shape:', df_api.shape)\n",
    "api_path = os.path.join(paths.raw, f\"api_yfinance_{ticker}_{_ts}.csv\")\n",
    "df_api.to_csv(api_path, index=False)\n",
    "print('Saved:', api_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10982758",
   "metadata": {},
   "source": [
    "# 2) Scrape S&P 500 table (Wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bcd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "html = requests.get(url, timeout=30).text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "table = soup.find('table', {'id': 'constituents'})\n",
    "rows = []\n",
    "for tr in table.tbody.find_all('tr')[1:]:\n",
    "    tds = [td.get_text(strip=True) for td in tr.find_all(['td','th'])]\n",
    "    rows.append(tds)\n",
    "cols = [th.get_text(strip=True) for th in table.thead.find_all('th')]\n",
    "df_spx = pd.DataFrame(rows, columns=cols)\n",
    "assert 'Symbol' in df_spx.columns and 'Security' in df_spx.columns\n",
    "print('Scrape shape:', df_spx.shape)\n",
    "scrape_path = os.path.join(paths.raw, f\"scrape_wikipedia_sp500_{_ts}.csv\")\n",
    "df_spx.to_csv(scrape_path, index=False)\n",
    "print('Saved:', scrape_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98f4ce",
   "metadata": {},
   "source": [
    "# 3) Document sources & simple validation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ac1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sources:')\n",
    "print('- API: yfinance for', ticker)\n",
    "print('- Scrape:', url)\n",
    "print('Validation: required columns present, shapes:', df_api.shape, df_spx.shape)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
